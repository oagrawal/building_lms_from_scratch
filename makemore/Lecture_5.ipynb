{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44e1b78d-9cdf-497a-8557-b3788ac95ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6a6f9f9-8306-44d9-994d-970b9149dc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n",
      "15\n",
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
     ]
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "print(len(words))\n",
    "print(max(len(w) for w in words))\n",
    "print(words[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0def269e-575d-4f32-bcc4-35f377eb2db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd58d031-a934-42aa-bb29-a0615d43df55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  \n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3598ded1-6242-4a9d-a08e-f8707e399290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function we will use later when comparing manual gradients to PyTorch gradients\n",
    "def cmp(s, dt, t):\n",
    "  ex = torch.all(dt == t.grad).item()\n",
    "  app = torch.allclose(dt, t.grad)\n",
    "  maxdiff = (dt - t.grad).abs().max().item()\n",
    "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b0e1637-9bf8-47f9-964c-2e5ae6ecbfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 64 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1 # using b1 just for fun, it's useless because of BN\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "# Note: I am initializating many of these parameters in non-standard ways\n",
    "# because sometimes initializating with e.g. all zeros could mask an incorrect\n",
    "# implementation of the backward pass.\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "296c5381-4893-49a0-a600-33a715280451",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size # a shorter variable also, for convenience\n",
    "# construct a minibatch\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "130aa0b1-ca52-447a-a8fb-bc4c6ac304ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3510, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "\n",
    "emb = C[Xb] # embed the characters into vectors\n",
    "embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "# Linear layer 1\n",
    "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "# BatchNorm layer\n",
    "bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "# Non-linearity\n",
    "h = torch.tanh(hpreact) # hidden layer\n",
    "# Linear layer 2\n",
    "logits = h @ W2 + b2 # output layer\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "  p.grad = None\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
    "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "         embcat, emb]:\n",
    "  t.retain_grad()\n",
    "loss.backward()\n",
    "loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1860df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 10]), torch.Size([27, 10]), torch.Size([32, 3]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape, C.shape, Xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ed25060-1cc6-44f2-bc68-9eac02382a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hpreact         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bngain          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnbias          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnraw           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar_inv       | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff2         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnmeani         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hprebn          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "embcat          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "emb             | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "C               | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: backprop through the whole thing manually, \n",
    "# backpropagating through exactly all of the variables \n",
    "# as they are defined in the forward pass above, one by one\n",
    "\n",
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(n), Yb] = -1.0 / n\n",
    "dprobs = (1 / probs) *  dlogprobs # boosting gradient\n",
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdims=True)\n",
    "dcounts = (counts_sum_inv * dprobs)\n",
    "dcounts_sum = -1 * (counts_sum**-2)  *  dcounts_sum_inv\n",
    "dcounts += (torch.ones_like(norm_logits) * dcounts_sum) \n",
    "dnorm_logits = counts * dcounts\n",
    "dlogits = dnorm_logits.clone() # clone for safety, will need to add later\n",
    "dlogit_maxes = (-1 * dnorm_logits).sum(1, keepdims=True) # should be 0, because we are only using dlogits_maxes for numerical stability, it doesn't contribute anything to the loss\n",
    "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes # (32 * 27) * (32 * 1)\n",
    "dh = dlogits @ W2.T\n",
    "dW2 = h.T @ dlogits\n",
    "db2 = dlogits.sum(0) # by default it throws out the empty dimension\n",
    "dhpreact = (1.0 - h**2) * dh # remember the derivative formula from micrograd!\n",
    "dbngain = (bnraw * dhpreact).sum(0, keepdims=True)\n",
    "dbnraw = bngain * dhpreact\n",
    "dbnbias = dhpreact.sum(0, keepdims=True)\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdims=True)\n",
    "dbndiff = bnvar_inv * dbnraw\n",
    "dbnvar = -0.5 *((bnvar + 1e-5) ** -1.5)* dbnvar_inv\n",
    "dbndiff2 = (1.0/(n-1)) * torch.ones_like(bndiff2) * dbnvar\n",
    "dbndiff += (2 * bndiff) * dbndiff2\n",
    "dhprebn = dbndiff.clone()\n",
    "dbnmeani = (-1 * dbndiff).sum(0, keepdims=True)\n",
    "dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n",
    "dembcat = dhprebn @ W1.T\n",
    "dW1 = embcat.T @ dhprebn\n",
    "db1 = dhprebn.sum(0)\n",
    "demb = dembcat.view(emb.shape)\n",
    "dC = torch.zeros_like(C)\n",
    "for r in range(emb.shape[0]):\n",
    "    for c in range(emb.shape[1]):\n",
    "        dC[Xb[r][c]] += demb[r][c]\n",
    "\n",
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "cmp('probs', dprobs, probs)\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "cmp('counts', dcounts, counts)\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
    "cmp('logits', dlogits, logits)\n",
    "cmp('h', dh, h)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('b2', db2, b2)\n",
    "cmp('hpreact', dhpreact, hpreact)\n",
    "cmp('bngain', dbngain, bngain)\n",
    "cmp('bnbias', dbnbias, bnbias)\n",
    "cmp('bnraw', dbnraw, bnraw)\n",
    "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "cmp('bnvar', dbnvar, bnvar)\n",
    "cmp('bndiff2', dbndiff2, bndiff2)\n",
    "cmp('bndiff', dbndiff, bndiff)\n",
    "cmp('bnmeani', dbnmeani, bnmeani)\n",
    "cmp('hprebn', dhprebn, hprebn)\n",
    "cmp('embcat', dembcat, embcat)\n",
    "cmp('W1', dW1, W1)\n",
    "cmp('b1', db1, b1)\n",
    "cmp('emb', demb, emb)\n",
    "cmp('C', dC, C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37f1f21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.351036310195923 diff: -2.384185791015625e-07\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: backprop through cross_entropy but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the loss,\n",
    "# take the derivative, simplify the expression, and just write it out\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# logit_maxes = logits.max(1, keepdim=True).values\n",
    "# norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "# counts = norm_logits.exp()\n",
    "# counts_sum = counts.sum(1, keepdims=True)\n",
    "# counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "# probs = counts * counts_sum_inv\n",
    "# logprobs = probs.log()\n",
    "# loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# now:\n",
    "loss_fast = F.cross_entropy(logits, Yb)\n",
    "print(loss_fast.item(), 'diff:', (loss_fast - loss).item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2be3de9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8, 14, 15, 22,  0, 19,  9, 14,  5,  1, 20,  3,  8, 14, 12,  0, 11,  0,\n",
       "        26,  9, 25,  0,  1,  1,  7, 18,  9,  3,  5,  9,  0, 18])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed511fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: False | approximate: True  | maxdiff: 6.984919309616089e-09\n"
     ]
    }
   ],
   "source": [
    "# dlogprobs = torch.zeros_like(logprobs)\n",
    "# dlogprobs[range(n), Yb] = -1.0 / n\n",
    "# dprobs = (1 / probs) *  dlogprobs # boosting gradient\n",
    "# dcounts_sum_inv = (counts * dprobs).sum(1, keepdims=True)\n",
    "# dcounts = (counts_sum_inv * dprobs)\n",
    "# dcounts_sum = -1 * (counts_sum**-2)  *  dcounts_sum_inv\n",
    "# dcounts += (torch.ones_like(norm_logits) * dcounts_sum) \n",
    "# dnorm_logits = counts * dcounts\n",
    "# dlogits = dnorm_logits.clone() # clone for safety, will need to add later\n",
    "# dlogit_maxes = (-1 * dnorm_logits).sum(1, keepdims=True) # should be 0, because we are only using dlogits_maxes for numerical stability, it doesn't contribute anything to the loss\n",
    "# dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes # (32 * 27) * (32 * 1)\n",
    "\n",
    "\n",
    "# backward pass\n",
    "\n",
    "dlogits = F.softmax(logits, 1) # find probs along rows\n",
    "dlogits[torch.arange(n), Yb] -= 1\n",
    "dlogits /= n\n",
    "\n",
    "cmp('logits', dlogits, logits) # I can only get approximate to be true, my maxdiff is 6e-9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d4e6b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26064e49250>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(dlogits.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e31a765e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n32 examples of 27 characters\\nblack square indicates the correct characters\\n\\n\\nintuitively we are pulling down on the wrong characters and pulling up on the incorrect characters\\nthe amount we push down on incorrect and push up on correct is the same (the sum of dlogits for each row is 0)\\n\\n\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "32 examples of 27 characters\n",
    "black square indicates the correct characters\n",
    "\n",
    "\n",
    "intuitively we are pulling down on the wrong characters and pulling up on the incorrect characters\n",
    "the amount we push down on incorrect and push up on correct is the same (the sum of dlogits for each row is 0)\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6304d758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max diff: tensor(4.7684e-07, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3: backprop through batchnorm but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the output of batchnorm,\n",
    "# take the derivative w.r.t. its input, simplify the expression, and just write it out\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "# bndiff = hprebn - bnmeani\n",
    "# bndiff2 = bndiff**2\n",
    "# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "# bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "# bnraw = bndiff * bnvar_inv\n",
    "# hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# now:\n",
    "hpreact_fast = bngain * (hprebn - hprebn.mean(0, keepdim=True)) / torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True) + 1e-5) + bnbias\n",
    "print('max diff:', (hpreact_fast - hpreact).abs().max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2584e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "\n",
    "# before we had:\n",
    "# dbnraw = bngain * dhpreact\n",
    "# dbndiff = bnvar_inv * dbnraw\n",
    "# dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "# dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "# dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
    "# dbndiff += (2*bndiff) * dbndiff2\n",
    "# dhprebn = dbndiff.clone()\n",
    "# dbnmeani = (-dbndiff).sum(0)\n",
    "# dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n",
    "\n",
    "# calculate dhprebn given dhpreact (i.e. backprop through the batchnorm)\n",
    "# (you'll also need to use some of the variables from the forward pass up above)\n",
    "\n",
    "# now\n",
    "dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "\n",
    "\n",
    "cmp('hprebn', dhprebn, hprebn) # I can only get approximate to be true, my maxdiff is 9e-10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e992db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12297\n",
      "      0/ 200000: 3.7932\n",
      "  10000/ 200000: 2.2055\n",
      "  20000/ 200000: 2.3798\n",
      "  30000/ 200000: 2.4544\n",
      "  40000/ 200000: 1.9862\n",
      "  50000/ 200000: 2.3561\n",
      "  60000/ 200000: 2.3519\n",
      "  70000/ 200000: 2.0542\n",
      "  80000/ 200000: 2.3711\n",
      "  90000/ 200000: 2.1424\n",
      " 100000/ 200000: 1.9349\n",
      " 110000/ 200000: 2.2606\n",
      " 120000/ 200000: 1.9823\n",
      " 130000/ 200000: 2.3847\n",
      " 140000/ 200000: 2.2810\n",
      " 150000/ 200000: 2.1436\n",
      " 160000/ 200000: 1.9847\n",
      " 170000/ 200000: 1.7666\n",
      " 180000/ 200000: 1.9904\n",
      " 190000/ 200000: 1.9243\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4: putting it all together!\n",
    "# Train the MLP neural net with your own backward pass\n",
    "\n",
    "# init\n",
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "\n",
    "# for p in parameters:\n",
    "#   p.requires_grad = True\n",
    "\n",
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "n = batch_size # convenience\n",
    "lossi = []\n",
    "\n",
    "# use this context manager for efficiency once your backward pass is written (TODO)\n",
    "with torch.no_grad():\n",
    "\n",
    "  # kick off optimization\n",
    "  for i in range(max_steps):\n",
    "\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb] # embed the characters into vectors\n",
    "    embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "    # Linear layer\n",
    "    hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "    # BatchNorm layer\n",
    "    # -------------------------------------------------------------\n",
    "    bnmean = hprebn.mean(0, keepdim=True)\n",
    "    bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
    "    bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "    bnraw = (hprebn - bnmean) * bnvar_inv\n",
    "    hpreact = bngain * bnraw + bnbias\n",
    "    # -------------------------------------------------------------\n",
    "    # Non-linearity\n",
    "    h = torch.tanh(hpreact) # hidden layer\n",
    "    logits = h @ W2 + b2 # output layer\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "      p.grad = None\n",
    "#     loss.backward() # use this for correctness comparisons, delete it later!\n",
    "\n",
    "    # manual backprop! #swole_doge_meme\n",
    "    # -----------------\n",
    "    \n",
    "    # loss to logits\n",
    "    dlogits = F.softmax(logits, 1) # find probs along rows\n",
    "    dlogits[torch.arange(n), Yb] -= 1\n",
    "    dlogits /= n\n",
    "    \n",
    "    # to second layer\n",
    "    dh = dlogits @ W2.T\n",
    "    dW2 = h.T @ dlogits\n",
    "    db2 = dlogits.sum(0) # by default it throws out the empty dimension\n",
    "    \n",
    "    # tanh layer backprop\n",
    "    dhpreact = (1.0 - h**2) * dh # remember the derivative formula from micrograd!\n",
    "    \n",
    "    # batchnorm backprop\n",
    "    dbngain = (bnraw * dhpreact).sum(0, keepdims=True)\n",
    "    dbnbias = dhpreact.sum(0, keepdims=True)\n",
    "    dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "\n",
    "    # 1st layer\n",
    "    dembcat = dhprebn @ W1.T\n",
    "    dW1 = embcat.T @ dhprebn\n",
    "    db1 = dhprebn.sum(0)\n",
    "    \n",
    "    # embeddings\n",
    "    demb = dembcat.view(emb.shape)\n",
    "    dC = torch.zeros_like(C)\n",
    "    for r in range(emb.shape[0]):\n",
    "        for c in range(emb.shape[1]):\n",
    "            dC[Xb[r][c]] += demb[r][c]\n",
    "            \n",
    "    grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
    "\n",
    "    # -----------------\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n",
    "    for p, grad in zip(parameters, grads):\n",
    "      #p.data += -lr * p.grad # old way of cheems doge (using PyTorch grad from .backward())\n",
    "      p.data += -lr * grad # new way of swole doge TODO: enable\n",
    "\n",
    "    # track stats\n",
    "    if i % 10000 == 0: # print every once in a while\n",
    "      print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "    lossi.append(loss.log10().item())\n",
    "\n",
    "#     if i >= 100: # TODO: delete early breaking when you're ready to train the full net\n",
    "#       break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0642de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, 10)        | exact: False | approximate: True  | maxdiff: 1.862645149230957e-08\n",
      "(30, 200)       | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n",
      "(200,)          | exact: False | approximate: True  | maxdiff: 5.587935447692871e-09\n",
      "(200, 27)       | exact: False | approximate: True  | maxdiff: 1.4901161193847656e-08\n",
      "(27,)           | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n",
      "(1, 200)        | exact: False | approximate: True  | maxdiff: 3.259629011154175e-09\n",
      "(1, 200)        | exact: False | approximate: True  | maxdiff: 5.587935447692871e-09\n"
     ]
    }
   ],
   "source": [
    "# useful for checking your gradients\n",
    "for p,g in zip(parameters, grads):\n",
    "  cmp(str(tuple(p.shape)), g, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5429259b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrate the batch norm at the end of training\n",
    "\n",
    "with torch.no_grad():\n",
    "  # pass the training set through\n",
    "  emb = C[Xtr]\n",
    "  embcat = emb.view(emb.shape[0], -1)\n",
    "  hpreact = embcat @ W1 + b1\n",
    "  # measure the mean/std over the entire training set\n",
    "  bnmean = hpreact.mean(0, keepdim=True)\n",
    "  bnvar = hpreact.var(0, keepdim=True, unbiased=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b9cc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate train and val loss\n",
    "\n",
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(split):\n",
    "  x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "  }[split]\n",
    "  emb = C[x] # (N, block_size, n_embd)\n",
    "  embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "  hpreact = embcat @ W1 + b1\n",
    "  hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "  h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "  logits = h @ W2 + b2 # (N, vocab_size)\n",
    "  loss = F.cross_entropy(logits, y)\n",
    "  print(split, loss.item())\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e8c122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample from the model\n",
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "      # ------------\n",
    "      # forward pass:\n",
    "      # Embedding\n",
    "      emb = C[torch.tensor([context])] # (1,block_size,d)      \n",
    "      embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "      hpreact = embcat @ W1 + b1\n",
    "      hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "      h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "      logits = h @ W2 + b2 # (N, vocab_size)\n",
    "      # ------------\n",
    "      # Sample\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "      context = context[1:] + [ix]\n",
    "      out.append(ix)\n",
    "      if ix == 0:\n",
    "        break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
